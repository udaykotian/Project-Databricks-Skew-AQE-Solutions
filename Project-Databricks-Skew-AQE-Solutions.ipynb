{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "725e8f81-6c86-4b9b-ad31-ebbca22c94cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Project-Databricks-Skew-AQE-Solutions\n",
    "\n",
    "## Objective\n",
    "Demonstrate how Adaptive Query Execution (AQE) in Apache Spark mitigates data skew in join operations using the Online Retail Dataset in Databricks. This project covers:\n",
    "- Configuring AQE and skew join optimization.\n",
    "- Performing a skewed join between a large dataset and a small table.\n",
    "- Analyzing AQE’s impact via the Spark UI.\n",
    "- Documenting findings for professional presentation or interviews.\n",
    "\n",
    "## Dataset\n",
    "- **Online Retail Dataset**: `/FileStore/tables/online_retail.csv`\n",
    "- Contains e-commerce transaction data with columns like `CustomerID`, `InvoiceNo`, `Quantity`, etc.\n",
    "- Likely to have skew (e.g., some `CustomerID` values have many transactions).\n",
    "\n",
    "## Best Practices\n",
    "- Modular code blocks for readability and reusability.\n",
    "- Descriptive Markdown cells for each step.\n",
    "- Structured for GitHub upload or interview presentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Configure AQE for Skew Handling\n",
    "- Enable AQE and skew join optimization to address data skew.\n",
    "- Set `spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes` to 256MB to split large partitions.\n",
    "- Keep default `spark.sql.adaptive.coalescePartitions.minPartitionSize` (1MB) unless small partitions are detected.\n",
    "- These settings are applied at the session level to guide AQE’s runtime optimizations (e.g., splitting skewed partitions, merging small ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5062882d-b06b-40d7-86e0-947c9197456d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQE Enabled: true\nSkew Join Enabled: true\nSkew Partition Threshold: 256MB\nMin Partition Size: 1048576b\n"
     ]
    }
   ],
   "source": [
    "# Configure AQE\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.skewJoin.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes\", \"256MB\")\n",
    "# Optional: Uncomment if small partitions are observed\n",
    "# spark.conf.set(\"spark.sql.adaptive.coalescePartitions.minPartitionSize\", \"10MB\")\n",
    "\n",
    "# Verify configurations\n",
    "print(\"AQE Enabled:\", spark.conf.get(\"spark.sql.adaptive.enabled\"))\n",
    "print(\"Skew Join Enabled:\", spark.conf.get(\"spark.sql.adaptive.skewJoin.enabled\"))\n",
    "print(\"Skew Partition Threshold:\", spark.conf.get(\"spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes\"))\n",
    "print(\"Min Partition Size:\", spark.conf.get(\"spark.sql.adaptive.coalescePartitions.minPartitionSize\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec616273-e38d-45b6-863a-396c6e363cfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Load the Online Retail Dataset\n",
    "- Load the CSV file into a DataFrame (`retail_df`).\n",
    "- Infer schema and include headers for accurate column names.\n",
    "- Display schema and sample data to verify loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89dee0ac-847f-4e28-a7d5-6d48c5142365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: string (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: integer (nullable = true)\n |-- Country: string (nullable = true)\n\n+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\n|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate |UnitPrice|CustomerID|Country       |\n+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\n|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |12/1/10 8:26|2.55     |17850     |United Kingdom|\n|536365   |71053    |WHITE METAL LANTERN                |6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |12/1/10 8:26|2.75     |17850     |United Kingdom|\n|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/10 8:26|3.39     |17850     |United Kingdom|\n+---------+---------+-----------------------------------+--------+------------+---------+----------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Load the Online Retail Dataset\n",
    "retail_df = spark.read.csv(\"/FileStore/tables/online_retail.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Display schema and sample data\n",
    "retail_df.printSchema()\n",
    "retail_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b994de9b-d47d-483b-8cd9-4391fd7159a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Create a Small Customer Table\n",
    "- Create a small DataFrame (`customer_df`) with `CustomerID` and `Name` to simulate a skewed join.\n",
    "- This table is intentionally small to mimic real-world scenarios where one table is smaller than the other, potentially exacerbating skew in the larger table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13e8d6ca-1143-4b86-89c4-904bcbd730b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|CustomerID| Name|\n+----------+-----+\n|         1|Alice|\n|         2|  Bob|\n|         3|Cathy|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Create a small customer table\n",
    "customer_data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Cathy\")]\n",
    "customer_df = spark.createDataFrame(customer_data, [\"CustomerID\", \"Name\"])\n",
    "\n",
    "# Display customer table\n",
    "customer_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "639c35a2-efea-49b4-a3a3-297b899e7f85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Perform Skewed Join with AQE\n",
    "- Join `retail_df` with `customer_df` on `CustomerID` using a left outer join.\n",
    "- The Online Retail Dataset may have skewed `CustomerID` values (e.g., some customers have many transactions).\n",
    "- AQE should detect and mitigate skew by splitting large partitions (threshold: 256MB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f09c3c24-9f24-48a9-8d54-fd0cb7728321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+-----------------------------------+--------+------------+---------+--------------+----+\n|CustomerID|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate |UnitPrice|Country       |Name|\n+----------+---------+---------+-----------------------------------+--------+------------+---------+--------------+----+\n|17850     |536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |12/1/10 8:26|2.55     |United Kingdom|null|\n|17850     |536365   |71053    |WHITE METAL LANTERN                |6       |12/1/10 8:26|3.39     |United Kingdom|null|\n|17850     |536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |12/1/10 8:26|2.75     |United Kingdom|null|\n|17850     |536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |12/1/10 8:26|3.39     |United Kingdom|null|\n|17850     |536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |12/1/10 8:26|3.39     |United Kingdom|null|\n+----------+---------+---------+-----------------------------------+--------+------------+---------+--------------+----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Perform the skewed join\n",
    "skewed_join_df = retail_df.join(customer_df, \"CustomerID\", \"left_outer\")\n",
    "\n",
    "# Display sample results\n",
    "skewed_join_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49c3b18b-ac50-484c-a1d3-09fecc3f2a8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5: Analyze Spark UI\n",
    "- Access the Spark UI via **Clusters > Spark UI** or the job execution link in the cell output.\n",
    "- **SQL Tab**: Verify `AdaptiveSparkPlan` and `SkewJoin` nodes in the query plan, indicating AQE is active and handling skew.\n",
    "- **Stages Tab**: Check task durations and input sizes to confirm AQE balanced the workload (e.g., split a 500MB partition into 100MB tasks).\n",
    "- Document findings below after reviewing the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1524bf0-60fa-432f-8d04-7d1c75986899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6: Spark UI Findings\n",
    "- **AQE Status**: Confirmed `AdaptiveSparkPlan (24)` in the SQL query plan, indicating AQE was active.\n",
    "- **Skew Handling**: No `SkewJoin` node detected; the dataset (48 rows from `retail_df`, 3 rows from `customer_df`) was too small (7.0 KiB total) to exceed the 256 MB skew threshold.\n",
    "- **Performance Impact**: \n",
    "  - **Task Durations**: Stage 9 (join) completed in 0.3s with 1 task, reflecting efficient execution for the small dataset.\n",
    "  - **Input Sizes**: Left side (`retail_df`) processed 7.0 KiB (48 rows), right side (`customer_df`) 96.0 B (3 rows); no splitting occurred due to size.\n",
    "- **Partition Merging**: Not applicable; the single task suggests no need for merging given the limited data.\n",
    "- **Observation**: AQE optimized the join by switching to a `BroadcastHashJoin`, leveraging the small `customer_df` size, completing in 4s overall. Skew handling wasn’t triggered due to the educational dataset size, aligning with our learning goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01f38338-7a3b-4492-a189-5117d17f254e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfec0010-92ea-4e4a-8ee6-085c09382bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a683523f-9024-43ee-8145-74b3aff100f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f50aa775-27fe-4168-950e-0aafb54dac79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a85ff43-6b33-4bc5-ad7f-5007c0c4f12d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Project-Databricks-Skew-AQE-Solutions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}